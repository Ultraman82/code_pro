{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "from os import walk\n",
    "import re\n",
    "import random\n",
    "from subprocess import call\n",
    "import cv2\n",
    "def image_ann(img_path, image_id, w, h):\n",
    "    return {'id': image_id,\n",
    "            'width': w,\n",
    "            'height': h,\n",
    "            'file_name': img_path,\n",
    "            'license': None,\n",
    "            'flickr_url': '',\n",
    "            'coco_url': None,\n",
    "            'date_captured': '2020-12-29T05:36:54Z'}\n",
    " \n",
    "def ann_gen(ann_id, image_id, cat_id, bbox):\n",
    "    return {'id': ann_id, 'image_id': image_id, 'category_id': cat_id, 'bbox': bbox, 'area': int(bbox[2] * bbox[3] / 100), 'iscrowd': 0}\n",
    "\n",
    "def json_image(json_path):\n",
    "    file_core = json_path.split('.')[0]\n",
    "    vid_class = file_core.split('-')[1]\n",
    "    core_path = os.path.join(vid_class, file_core)\n",
    "    files = os.listdir(core_path)    \n",
    "    indices = range(len(files))\n",
    "    if len(files) > 2:        \n",
    "        indices = random.sample(range(len(files)), 3)\n",
    "    files = [os.path.join(core_path, files[i]) for i in indices]            \n",
    "    return zip(files, indices)\n",
    "def generate_ann(total_image_path, breed, bbox, width, height):\n",
    "    temp = {}\n",
    "    temp['image_path'] = total_image_path\n",
    "    temp['breed'] = breed\n",
    "    temp['bbox'] = bbox\n",
    "    temp['width'] = width\n",
    "    temp['height'] = height\n",
    "    return temp\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# root_dir = '/media/edgar/ybuntu/pet_data/공유_Data_Export'\n",
    "root_dir = './'\n",
    "img_dir_prefix = '_frames_fps_5_start_-1.00_end_-1.00_'\n",
    "result = {}\n",
    "for (root, dirs, files) in os.walk(root_dir):\n",
    "    for afile in files:        \n",
    "        if afile.endswith('json'):\n",
    "            json_path = os.path.join(root, afile)            \n",
    "            file_core = afile.split('_')[-1].split('.')[0]\n",
    "            img_dir = img_dir_prefix + file_core + \"_mp4\"\n",
    "            img_path = os.path.join(root, img_dir)\n",
    "            file_len = len(glob.glob(img_path + \"/*.jpg\"))             \n",
    "            with open(json_path) as json_file:\n",
    "                data = json.load(json_file)\n",
    "                try:\n",
    "                    anns = data['annotations']\n",
    "                    metadata = data['metadata']\n",
    "                    breed = metadata['animal']['breed']\n",
    "                    width = metadata['width']\n",
    "                    height = metadata['height']\n",
    "                    for ann in anns:\n",
    "                        frame = ann['frame_number']\n",
    "                        timestamp = ann['timestamp']                                        \n",
    "                        img_name = f'frame_{frame}_timestamp_{timestamp}.jpg' \n",
    "                        total_image_path = os.path.join(img_path, img_name)\n",
    "                        if os.path.isfile(total_image_path):            \n",
    "                            bbox = ann['bounding_box']\n",
    "                            bbox = [bbox['x'], bbox['y'], bbox['width'], bbox['height']]            \n",
    "                            if breed not in result.keys(): \n",
    "                                result[breed] = []                            \n",
    "                            result[breed].append(generate_ann(total_image_path[2:], breed, bbox, width, height))\n",
    "                except:\n",
    "                    print('something went wrong')\n",
    "len(result)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {}\n",
    "images = []\n",
    "annotations = []\n",
    "img_id = 0\n",
    "category_id = 0\n",
    "ann_id = 0\n",
    "\n",
    "def generate_ann_block(cat_list):        \n",
    "    global test \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATIO = 0.1\n",
    "\n",
    "for cat_name in result:\n",
    "    cat_list = result[cat_name]\n",
    "    # if len(cat_list) > 1000:\n",
    "    if len(cat_list) > 10:\n",
    "        split_point = int(len(result[cat_name]) * SAMPLING_RATIO)\n",
    "        random.shuffle(cat_list)\n",
    "        sampled_list = cat_list[:split_point]\n",
    "        for ann in sampled_list:        \n",
    "            bbox = ann['bbox']\n",
    "            breed = ann['breed']\n",
    "            height = ann[\"height\"]\n",
    "            width = ann[\"width\"]        \n",
    "            image_path = ann['image_path']\n",
    "            if breed not in categories.keys():\n",
    "                categories[breed] = category_id\n",
    "                category_id += 1\n",
    "            images.append(image_ann(image_path, img_id, width, height))            \n",
    "            annotations.append(ann_gen(ann_id, img_id, categories[breed], bbox))\n",
    "            img_id +=1\n",
    "            ann_id +=1\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'id': 0, 'name': '셔틀랜드 쉽독', 'supercategory': 'object'},\n",
       " {'id': 1, 'name': '믹스견', 'supercategory': 'object'},\n",
       " {'id': 2, 'name': '포메라니안', 'supercategory': 'object'},\n",
       " {'id': 3, 'name': '파피용', 'supercategory': 'object'},\n",
       " {'id': 4, 'name': '코리안 숏헤어', 'supercategory': 'object'},\n",
       " {'id': 5, 'name': '노르웨이숲', 'supercategory': 'object'},\n",
       " {'id': 6, 'name': '푸들', 'supercategory': 'object'},\n",
       " {'id': 7, 'name': '스코티쉬 폴드', 'supercategory': 'object'},\n",
       " {'id': 8, 'name': '러시안블루', 'supercategory': 'object'},\n",
       " {'id': 9, 'name': '브리티쉬 숏헤어', 'supercategory': 'object'},\n",
       " {'id': 10, 'name': '미니어처 핀셔', 'supercategory': 'object'},\n",
       " {'id': 11, 'name': '치와와', 'supercategory': 'object'},\n",
       " {'id': 12, 'name': '말티즈', 'supercategory': 'object'},\n",
       " {'id': 13, 'name': '프렌치 불독', 'supercategory': 'object'},\n",
       " {'id': 14, 'name': '스코티쉬 폴드 롱헤어', 'supercategory': 'object'},\n",
       " {'id': 15, 'name': '닥스훈트', 'supercategory': 'object'},\n",
       " {'id': 16, 'name': '비숑 프리제', 'supercategory': 'object'},\n",
       " {'id': 17, 'name': '웰시 코기 (펨브록)', 'supercategory': 'object'},\n",
       " {'id': 18, 'name': '벵갈', 'supercategory': 'object'},\n",
       " {'id': 19, 'name': '시추', 'supercategory': 'object'},\n",
       " {'id': 20, 'name': '먼치킨 롱헤어', 'supercategory': 'object'},\n",
       " {'id': 21, 'name': '래그돌', 'supercategory': 'object'},\n",
       " {'id': 22, 'name': '먼치킨', 'supercategory': 'object'},\n",
       " {'id': 23, 'name': '진돗개', 'supercategory': 'object'},\n",
       " {'id': 24, 'name': '터키시 앙고라', 'supercategory': 'object'},\n",
       " {'id': 25, 'name': '아비시니안', 'supercategory': 'object'},\n",
       " {'id': 26, 'name': '풍산개', 'supercategory': 'object'},\n",
       " {'id': 27, 'name': '보스턴 테리어', 'supercategory': 'object'},\n",
       " {'id': 28, 'name': '재패니스 스피츠', 'supercategory': 'object'},\n",
       " {'id': 29, 'name': '래브라도 리트리버', 'supercategory': 'object'},\n",
       " {'id': 30, 'name': '웰시 코기 (카디건)', 'supercategory': 'object'},\n",
       " {'id': 31, 'name': '시베리안 허스키', 'supercategory': 'object'},\n",
       " {'id': 32, 'name': '페르시안', 'supercategory': 'object'},\n",
       " {'id': 33, 'name': '시바', 'supercategory': 'object'},\n",
       " {'id': 34, 'name': '시암', 'supercategory': 'object'},\n",
       " {'id': 35, 'name': '요크셔 테리어', 'supercategory': 'object'},\n",
       " {'id': 36, 'name': '페키니즈', 'supercategory': 'object'},\n",
       " {'id': 37, 'name': '스코티쉬 스트레이드', 'supercategory': 'object'},\n",
       " {'id': 38, 'name': '골든 리트리버', 'supercategory': 'object'},\n",
       " {'id': 39, 'name': '스코티쉬 스트레이드 롱헤어', 'supercategory': 'object'},\n",
       " {'id': 40, 'name': '도베르만', 'supercategory': 'object'},\n",
       " {'id': 41, 'name': '스노우슈', 'supercategory': 'object'},\n",
       " {'id': 42, 'name': '삽살개', 'supercategory': 'object'},\n",
       " {'id': 43, 'name': '라팜 숏헤어', 'supercategory': 'object'},\n",
       " {'id': 44, 'name': '아메리칸 숏헤어', 'supercategory': 'object'},\n",
       " {'id': 45, 'name': '베들링턴 테리어', 'supercategory': 'object'},\n",
       " {'id': 46, 'name': '독일 스피츠', 'supercategory': 'object'},\n",
       " {'id': 47, 'name': '이탈리안 그레이하운드', 'supercategory': 'object'},\n",
       " {'id': 48, 'name': '피니시 스피츠', 'supercategory': 'object'},\n",
       " {'id': 49, 'name': '오스트레일리안 실키 테리어', 'supercategory': 'object'},\n",
       " {'id': 50, 'name': '미니어처 슈나우저', 'supercategory': 'object'},\n",
       " {'id': 51, 'name': '아메리칸 코커 스패니얼', 'supercategory': 'object'},\n",
       " {'id': 52, 'name': '엑조틱 숏헤어', 'supercategory': 'object'},\n",
       " {'id': 53, 'name': '비글', 'supercategory': 'object'},\n",
       " {'id': 54, 'name': '버마', 'supercategory': 'object'},\n",
       " {'id': 55, 'name': '스탠다드 푸들', 'supercategory': 'object'},\n",
       " {'id': 56, 'name': '보더 콜리', 'supercategory': 'object'},\n",
       " {'id': 57, 'name': '사모예드견', 'supercategory': 'object'}]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "json_categories = []\n",
    "for i in categories:\n",
    "    obj = {}\n",
    "    obj['id'] = categories[i]\n",
    "    # obj['name'] = str(categories[i])\n",
    "    obj['name'] = i\n",
    "    obj['supercategory'] = 'object'\n",
    "    json_categories.append(obj)\n",
    "json_categories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "54004"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "len(images)\n",
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## image_save\n",
    "# font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "# org = (50, 50)\n",
    "# color = (255, 0, 0)\n",
    "# nu_image = 100\n",
    "# for i in range(100):    \n",
    "#     bbox = annotations[i]['bbox']\n",
    "#     image_path = images[i]['file_name']\n",
    "#     img = cv2.imread(image_path)\n",
    "#     startpoint = (bbox[0], bbox[1])\n",
    "#     endpoint = (bbox[0] + bbox[2], bbox[1] + bbox[3])\n",
    "#     image = cv2.rectangle(img, startpoint, endpoint, color, 2)    \n",
    "#     image = cv2.putText(image, str(bbox), org, font, 2, color, 2, cv2.LINE_AA) \n",
    "#     file_core = image_path.split('/')[-2].split('_')[-2] + \"_\"\n",
    "#     test_path = 'tester/' + file_core + image_path.split('/')[-1]\n",
    "#     cv2.imwrite(test_path, image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_result = {}\n",
    "json_result[\"info\"] = {\"year\": 2021, \"date_created\": \"2020-12-28T07:22:18Z\", \"version\": \"1.0\", \"description\": \"test None\", \"contributor\": \"\", \"url\": \"https://app.hasty.ai/projects/fe3692c9-5502-4c07-8ea1-f0e034a9ed02\"}\n",
    "json_result['licenses'] = []\n",
    "json_result['categories'] = json_categories\n",
    "json_result['images'] = images\n",
    "json_result['annotations'] = annotations\n",
    "with open('breed2.json', 'w') as outfile:\n",
    "    json.dump(json_result, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7520"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "len(annotations)\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'valRaw' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-1699de56a1f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val583_82.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mclss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalRaw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalRaw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valRaw' is not defined"
     ]
    }
   ],
   "source": [
    "with open('val583_82.txt', 'w') as f:\n",
    "    for clss in valRaw:\n",
    "        for item in valRaw[clss]:\n",
    "            f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tailing/dog-tailing-002676\n",
      "tailing/dog-tailing-001596\n",
      "tailing/dog-tailing-001484\n",
      "feetup/dog-feetup-003034\n",
      "tailing/dog-tailing-002963\n",
      "heading/dog-heading-000547\n",
      "sitdown/cat-sitdown-000009\n",
      "tailing/dog-tailing-001583\n",
      "lying/dog-lying-002927\n",
      "footup/dog-footup-001791\n",
      "footup/dog-footup-001149\n",
      "lying/dog-lying-001544\n",
      "footup/dog-footup-001598\n",
      "feetup/dog-feetup-001524\n",
      "bodylower/dog-bodylower-000119\n",
      "bodylower/dog-bodylower-001749\n",
      "bodylower/dog-bodylower-002664\n",
      "lying/dog-lying-000347\n",
      "feetup/dog-feetup-002924\n",
      "walkrun/dog-walkrun-002944\n",
      "sit/dog-sit-000677\n",
      "footpush/cat-footpush-000231\n",
      "footup/dog-footup-000597\n",
      "walkrun/dog-walkrun-003014\n",
      "sit/dog-sit-000437\n",
      "heading/dog-heading-000547\n",
      "lying/dog-lying-000955\n",
      "bodylower/dog-bodylower-001646\n"
     ]
    }
   ],
   "source": [
    "path = \"./annotations\"\n",
    "file_list = os.listdir(path)\n",
    "check_list = []\n",
    "for json_file in file_list:\n",
    "    json_path = os.path.join(path, json_file)\n",
    "    with open(json_path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        file_name = data['file_video'].split('/')[1].split('.')[0]\n",
    "        class_name = file_name.split('-')[1]\n",
    "        file_path = os.path.join(class_name, file_name)\n",
    "        # searching numbering 00000 and add 1 to all the files in the dir\n",
    "        # if len(glob.glob(file_path + \"/*00000.jpg\")):\n",
    "        #     temp_list = sorted(os.listdir(file_path))\n",
    "        #     for rev in temp_list[::-1]:                \n",
    "        #         src = os.path.join(file_path, rev)                \n",
    "        #         num_str = re.findall('[0-9]+', rev)[0]\n",
    "        #         changed_num = int(num_str) + 1\n",
    "        #         dst = file_path + \"/img_\" + str('{:05d}'.format(changed_num)) + '.jpg'\n",
    "        #         os.rename(src, dst)\n",
    "        \n",
    "        # check the number of downloaded file is matched with annotation count\n",
    "        actual_num_file = len(glob.glob(file_path + \"/*jpg\"))\n",
    "        annotation_num_file = len(data['annotations'])\n",
    "        if actual_num_file is not annotation_num_file:\n",
    "            cnt = actual_num_file\n",
    "            cur_data = data['annotations'][cnt - 1:]\n",
    "            print(file_path)\n",
    "            for line in cur_data:\n",
    "                print(\"{} is miss matched {} : {}\".format(file_path, annotation_num_file, actual_num_file))\n",
    "                url = line[\"frame_url\"]\n",
    "                current_file_name = file_path + \"/img_\" + str('{:05d}'.format(cnt)) + '.jpg'                \n",
    "                r = requests.get(url)\n",
    "                open(current_file_name, 'wb').write(r.content)    \n",
    "                print(\"saved {}\".format(current_file_name))\n",
    "                cnt += 1\n",
    "            \n",
    "        check_list.append((annotation_num_file, file_name))\n",
    "        \n",
    "        \n",
    "        # print(len(data['annotations']))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "941"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "len(check_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object detection Train set\n",
    "CNT = 10\n",
    "with open('train10_obj.txt', 'w') as f:\n",
    "    for clss in trainRaw:\n",
    "        for item in trainRaw[clss]:\n",
    "            file_path, frames, clss = item.split(' ')            \n",
    "            file_list = os.listdir(file_path)\n",
    "            sampling = random.choices(file_list, k=CNT)\n",
    "            # print(clss)\n",
    "            if clss == 'cat':\n",
    "                clss = '0'                \n",
    "            else:\n",
    "                clss = '1'                \n",
    "\n",
    "            for itemf in sampling:\n",
    "                f.write(\"{}\\n\".format(os.path.join(file_path,itemf, clss)))\n",
    "            \n",
    "            # for dir_path in classes[clss]:        \n",
    "            #     file_list = os.listdir(file_path)\n",
    "            #     sampling = random.choices(file_list, k=5)\n",
    "            #     print(sampling)\n",
    "            #     f.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object detection Val set\n",
    "with open('val10_obj.txt', 'w') as f:\n",
    "    for clss in valRaw:\n",
    "        for item in valRaw[clss]:\n",
    "            file_path, frames, clss = item.split(' ')            \n",
    "            file_list = os.listdir(file_path)\n",
    "            sampling = random.choices(file_list, k=CNT)\n",
    "            # print(clss)\n",
    "            if clss == 'cat':\n",
    "                clss = '0'                \n",
    "            else:\n",
    "                clss = '1'                \n",
    "\n",
    "            for itemf in sampling:\n",
    "                f.write(\"{}\\n\".format(os.path.join(file_path,itemf, clss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}